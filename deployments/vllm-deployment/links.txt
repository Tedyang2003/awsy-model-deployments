

Triton Server External and Internal model generation API (Change Accordingly)
---------------------------------------------------------
Internal API: http://triton-is-predictor.triton-inference-services.svc.cluster.local:8080/v2/models/meta-llama-3-8b-instruct-awq/generate

External API : http://triton-route-triton-inference-services.apps.nebula.sl/v2/models/meta-llama-3-8b-instruct-awq/generate


VLLM configuration Document
--------------------------------
https://docs.google.com/document/d/15vuuft9BbzPbVfgBlAr39kQjfZrFrE157gJ93R6zAJY/edit?tab=t.0


Helm Deployment Document
--------------------------------
https://www.linkedin.com/pulse/creating-your-own-helm-chart-repo-integrating-sumit-mukherjee-rjkfc
