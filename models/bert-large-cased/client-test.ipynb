{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert-large-cased-finetuned-conll03-english Deployment\n",
    "\n",
    "### Model Description\n",
    "The dbmdz/bert-large-cased-finetuned-conll03-english model is a variant of BERT (Bidirectional Encoder Representations from Transformers) specifically fine-tuned on the CONLL-03 dataset for Named Entity Recognition (NER) tasks. \n",
    "\n",
    "It is built using the large cased version of BERT, which means the model is case-sensitive and can distinguish between words with different capitalizations. However BERT was originally for text masking, hence we cannot follow their tutorial for set up https://huggingface.co/google-bert/bert-large-cased, which uses 'fill-mask'. Instead we need to use 'token-classification'\n",
    "\n",
    "---\n",
    "\n",
    "### Model Interaction\n",
    "This model is meant to be a entitiy recognizer, meaning it is able to identify important tokens in a text. It will then return a list of these words, their scores as well as what category of entity they are e.g person, place and etc\n",
    "\n",
    "**Example Input**:\n",
    "\n",
    "\"My name is Sarah and I live in London\"\n",
    "\n",
    "**Example Output**:\n",
    "\n",
    "[{'entity': 'I-PER',\n",
    "  'score': 0.9986294507980347,\n",
    "  'index': 4,\n",
    "  'word': 'Sarah',\n",
    "  'start': 11,\n",
    "  'end': 16},\n",
    " {'entity': 'I-LOC',\n",
    "  'score': 0.9990901947021484,\n",
    "  'index': 9,\n",
    "  'word': 'London',\n",
    "  'start': 31,\n",
    "  'end': 37},]\n",
    "\n",
    "**Per is person, Loc is location**\n",
    "\n",
    "---\n",
    "\n",
    "### Current Deployment\n",
    "\n",
    "For this current deployment, it will accept 1 string per request, but since triton does not natively support the return of objects, I have made it convert the object into a string instead before returning. The client can then run json.loads to turn it back into an object\n",
    "\n",
    "Used the vllm method of deployment to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_url = \"http://triton-route-triton-inference-services.apps.nebula.sl/v2/models/bert-large-cased/infer\"\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"INPUT\",\n",
    "            \"shape\": [1], \n",
    "            \"datatype\": \"BYTES\",  # Make sure the datatype matches the input configuration\n",
    "            \"data\": [   \n",
    "                \"My name is Sarah and I live in London, while Steve lives in Greece.\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"name\": \"OUTPUT\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Step 4: Send the POST request to Triton\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(triton_url, json=payload, headers=headers)\n",
    "\n",
    "# Step 5: Handle the response\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "\n",
    "else:\n",
    "    print(f\"Error with Triton request. Status code: {response.status_code}\")\n",
    "    print(f\"Error message: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.9986294507980347,\n",
       "  'index': 4,\n",
       "  'word': 'Sarah',\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9990901947021484,\n",
       "  'index': 9,\n",
       "  'word': 'London',\n",
       "  'start': 31,\n",
       "  'end': 37},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9976377487182617,\n",
       "  'index': 12,\n",
       "  'word': 'Steve',\n",
       "  'start': 45,\n",
       "  'end': 50},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9997974038124084,\n",
       "  'index': 15,\n",
       "  'word': 'Greece',\n",
       "  'start': 60,\n",
       "  'end': 66}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_object = json.loads(response_data['outputs'][0]['data'][0])\n",
    "json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
