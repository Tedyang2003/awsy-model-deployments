{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39m_validate_not_a_forked_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a,b,c: \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\StarLabs\\production-deployments\\env\\Lib\\site-packages\\torch\\__init__.py:262\u001b[0m\n\u001b[0;32m    258\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    260\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 262\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Projects\\StarLabs\\production-deployments\\env\\Lib\\site-packages\\torch\\__init__.py:238\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    236\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 238\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "# load model; We are going to use a pretrained resnet model\n",
    "model = models.resnet50(pretrained=True).eval()\n",
    "x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                        # model being run\n",
    "                  x,                            # model input (or a tuple for multiple inputs)\n",
    "                  \"./classifier/model.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,           # store the trained parameter weights inside the model file\n",
    "                  input_names = ['input'],      # the model's input names\n",
    "                  output_names = ['output'],    # the model's output names\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "# load model; We are going to use a pretrained resnet model\n",
    "model = models.resnet50(pretrained=True).eval()\n",
    "x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                        # model being run\n",
    "                  x,                            # model input (or a tuple for multiple inputs)\n",
    "                  \"./classifier_2/model.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,           # store the trained parameter weights inside the model file\n",
    "                  input_names = ['input'],      # the model's input names\n",
    "                  output_names = ['output_2'],    # the model's output names\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "# load model; We are going to use a pretrained resnet model\n",
    "model = models.resnet50(pretrained=True).eval()\n",
    "x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                        # model being run\n",
    "                  x,                            # model input (or a tuple for multiple inputs)\n",
    "                  \"./classifier_3/model.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,           # store the trained parameter weights inside the model file\n",
    "                  input_names = ['input'],      # the model's input names\n",
    "                  output_names = ['output_3'],    # the model's output names\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
